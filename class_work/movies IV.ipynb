{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"latex_metadata":{"author":"Andreas C. M\\\"ller","title":"Machine Learning with Python"},"colab":{"name":"movies IV.ipynb","provenance":[{"file_id":"1FOF-duTJaWYQbe5YSXyFoNWQm2cZpI59","timestamp":1604608289728}],"collapsed_sections":["Yz_yQe_fED-H","4OwFh4ZaEUlR","gydX7SQnEn4H","vJqQvvjdHIHm"]}},"cells":[{"cell_type":"code","metadata":{"id":"bCfxffcRLeP3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636401193954,"user_tz":420,"elapsed":23934,"user":{"displayName":"Abe Burton","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01633280074345084238"}},"outputId":"08a3a8dc-32fb-455f-db65-76f3ad60c548"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","metadata":{"id":"gzWRbYOjLAIr"},"source":["# Example: Instrumental Variables Estimation of the Effect of Social Spillovers on Movie-going"]},{"cell_type":"markdown","metadata":{"id":"bTaCceX9LAIs"},"source":["This notebook will illustrate the entire supervised machine learning process in the context of predicting movie attendance based on the weather on opening weekend."]},{"cell_type":"markdown","metadata":{"id":"nmC-h_PvLAIs"},"source":["### Figure out your question"]},{"cell_type":"markdown","metadata":{"id":"HZ62RUB5LAIt"},"source":["What is the effect of opening-weekend attendance on subsequent weekend attendance at a movie?"]},{"cell_type":"markdown","metadata":{"id":"gfaGY7UHLAIt"},"source":["## Obtain a labeled dataset"]},{"cell_type":"code","metadata":{"id":"4mQtzrcRLAIu"},"source":["import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E1XtvSKZLAIx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636401245633,"user_tz":420,"elapsed":755,"user":{"displayName":"Abe Burton","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01633280074345084238"}},"outputId":"c841119c-797c-4218-bb24-b9d5c04383de"},"source":["moviedata=pd.read_csv('/content/gdrive/My Drive/Econ 484/datasets/movies_cleaned.csv')\n","print(moviedata.head())\n","print(\"Shape: {}\".format(str(moviedata.shape)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   x_openingsales  open_res_own_snow_6  ...  open_res_own_prec_5_0  y_ticketsales\n","0        0.441295             0.035468  ...               0.068204       0.231157\n","1        2.056574             0.001406  ...              -0.024064       1.293781\n","2        1.516240             0.003928  ...              -0.016685       0.973964\n","3        5.888784             0.104670  ...               0.058988       3.219681\n","4        3.570493             0.071977  ...              -0.003570       2.345072\n","\n","[5 rows x 54 columns]\n","Shape: (1671, 54)\n"]}]},{"cell_type":"markdown","metadata":{"id":"VttS4Ca0LAIz"},"source":["Let's define our \"label\" (y) vector, our \"treatment\" vector (d), and our instrument matrix (Z):"]},{"cell_type":"code","metadata":{"id":"rv0M75IWLAIz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636401274243,"user_tz":420,"elapsed":430,"user":{"displayName":"Abe Burton","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01633280074345084238"}},"outputId":"06d802be-a32c-444d-e222-6d5bf1d2db44"},"source":["y = moviedata.loc[:,'y_ticketsales']\n","d = moviedata.loc[:,['x_openingsales']]\n","Z = moviedata.filter(like='open_',axis=1)\n","print('our y vector is:\\n',y.head)\n","print('our d vector is:\\n',d.head)\n","print('our instrument matrix is:\\n',Z.head)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["our y vector is:\n"," <bound method NDFrame.head of 0       0.231157\n","1       1.293781\n","2       0.973964\n","3       3.219681\n","4       2.345072\n","          ...   \n","1666    3.459683\n","1667    3.373921\n","1668    1.825269\n","1669    1.152968\n","1670    1.050490\n","Name: y_ticketsales, Length: 1671, dtype: float64>\n","our d vector is:\n"," <bound method NDFrame.head of       x_openingsales\n","0           0.441295\n","1           2.056574\n","2           1.516240\n","3           5.888784\n","4           3.570493\n","...              ...\n","1666        9.754463\n","1667        6.293130\n","1668        2.908898\n","1669        1.672062\n","1670        3.026325\n","\n","[1671 rows x 1 columns]>\n","our instrument matrix is:\n"," <bound method NDFrame.head of       open_res_own_snow_6  ...  open_res_own_prec_5_0\n","0                0.035468  ...               0.068204\n","1                0.001406  ...              -0.024064\n","2                0.003928  ...              -0.016685\n","3                0.104670  ...               0.058988\n","4                0.071977  ...              -0.003570\n","...                   ...  ...                    ...\n","1666            -0.031120  ...              -0.001423\n","1667            -0.031120  ...              -0.001423\n","1668             0.058353  ...              -0.000004\n","1669             0.058353  ...              -0.000004\n","1670             0.058353  ...              -0.000004\n","\n","[1671 rows x 52 columns]>\n"]}]},{"cell_type":"markdown","metadata":{"id":"Mz_KFucyLAI1"},"source":["## Start with OLS of y on d. Be sure to print import necessary packages and print out coefficients!"]},{"cell_type":"markdown","metadata":{"id":"5JkIkrXLD9tZ"},"source":["### Try yourself first!"]},{"cell_type":"code","metadata":{"id":"Dcbm056vECAo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636401675608,"user_tz":420,"elapsed":232,"user":{"displayName":"Abe Burton","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01633280074345084238"}},"outputId":"f3830e89-f85a-4694-f608-371348ba5e46"},"source":["from sklearn import linear_model\n","\n","ols = linear_model.LinearRegression()\n","ols_reg = ols.fit(d,y)\n","print('OLS coefficient: ',ols_reg.coef_)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["OLS coefficient:  [0.4712296]\n"]}]},{"cell_type":"markdown","metadata":{"id":"Yz_yQe_fED-H"},"source":["### Cheat if you need to"]},{"cell_type":"code","metadata":{"id":"aq1fmWdjLAI2"},"source":["from sklearn import linear_model\n","\n","ols = linear_model.LinearRegression()\n","ols_reg = ols.fit(d,y)\n","print('OLS coefficient: ',ols_reg.coef_)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wuZh-g9SLAI4"},"source":["## Now do \"manual\" two-stage least squares where you first regress d on Z, obtain predicted values, then regress y on the predicted values. Be sure to print out final coefficient on d-hat!"]},{"cell_type":"markdown","metadata":{"id":"8ZTmzjfJEOoi"},"source":["### Try yourself first"]},{"cell_type":"code","metadata":{"id":"xMhPvrwUETWC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636401936142,"user_tz":420,"elapsed":316,"user":{"displayName":"Abe Burton","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01633280074345084238"}},"outputId":"8fac6f8b-a554-4db1-b062-002911b8a05f"},"source":["first_stage = linear_model.LinearRegression().fit(Z,d)\n","d_hat = first_stage.predict(Z)\n","second_stage = linear_model.LinearRegression().fit(d_hat,y)\n","print(second_stage.coef_)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.55182418]\n"]}]},{"cell_type":"markdown","metadata":{"id":"4OwFh4ZaEUlR"},"source":["### Cheat if you need to"]},{"cell_type":"code","metadata":{"id":"8wkQST25LAI4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636401942178,"user_tz":420,"elapsed":307,"user":{"displayName":"Abe Burton","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01633280074345084238"}},"outputId":"d3d5583a-a4b6-4f09-c708-fa78ad871ebd"},"source":["ols_fs = ols.fit(Z,d)\n","dhat = ols_fs.predict(Z)\n","tsls = ols.fit(dhat,y)\n","print('2SLS coefficient: ',tsls.coef_)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2SLS coefficient:  [0.55182418]\n"]}]},{"cell_type":"markdown","metadata":{"id":"1NbHlQq6LAI6"},"source":["## Now do ML-augmented two-stage least squares using Random Forest to obtain the fitted values"]},{"cell_type":"markdown","metadata":{"id":"FXvhRSEKEkqG"},"source":["###Try yourself first"]},{"cell_type":"code","metadata":{"id":"lBAv8dojEnXI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636403530526,"user_tz":420,"elapsed":542,"user":{"displayName":"Abe Burton","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01633280074345084238"}},"outputId":"a0d3e243-3647-40de-dca5-f3226248130b"},"source":["# import necessary packages and create prediction \"object\"\n","# first grow random forest: create d-hat that is less overfit as ols\n","####EXPLANATION OF WHY THIS WORKS CORRECTLY in MY WRITTEN NOTES\n","from sklearn.ensemble import RandomForestRegressor\n","tree = RandomForestRegressor(max_depth=2, max_features='sqrt').fit(Z,d)\n","\n","#Then use d_hat in 2sls. so then you get a new d_hat ols and regress it on y\n","# now get random forest predictions to use as instrument:\n","predictions = tree.predict(Z)\n","print(predictions)\n","# do \"first stage\" using random forest predictions as instrument:\n","fstage = linear_model.LinearRegression().fit(np.reshape(predictions,(-1,1)),d)\n","fstage_hat = fstage.predict(np.reshape(predictions,(-1,1)))\n","# finally, 2nd stage regression:\n","second = linear_model.LinearRegression().fit(fstage_hat,y)\n","print(second.coef_)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  after removing the cwd from sys.path.\n"]},{"output_type":"stream","name":"stdout","text":["[2.48262527 2.43507865 2.55821101 ... 2.41848227 2.41848227 2.41848227]\n","[0.44975107]\n"]}]},{"cell_type":"markdown","metadata":{"id":"gydX7SQnEn4H"},"source":["### Cheat"]},{"cell_type":"code","metadata":{"id":"cnlGCM31Jqhm"},"source":["# import necessary packages and create prediction \"object\"\n","from sklearn.ensemble import RandomForestRegressor\n","rf = RandomForestRegressor(max_depth=2,max_features='sqrt')\n","# first grow random forest:\n","rf_fs=rf.fit(Z,np.ravel(d))\n","# now get random forest predictions to use as instrument:\n","iv_rf=np.reshape(rf_fs.predict(Z),(-1,1))\n","# do \"first stage\" using random forest predictions as instrument:\n","fs_rf=ols.fit(iv_rf,d)\n","dhat_rf=fs_rf.predict(iv_rf)\n","# finally, 2nd stage regression:\n","tsls_rf=ols.fit(np.reshape(dhat_rf,(-1,1)),y)\n","print('2SLS+Random Forest coefficient: ',tsls_rf.coef_)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K-6n2i-JFy-k"},"source":["##Now do Belloni, Chernozhukov, Hansen Post-Lasso 2SLS"]},{"cell_type":"markdown","metadata":{"id":"yhlMf_FDHEWj"},"source":["### Try yourself first"]},{"cell_type":"code","metadata":{"id":"sScVyTNZHG-3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636404341298,"user_tz":420,"elapsed":309,"user":{"displayName":"Abe Burton","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01633280074345084238"}},"outputId":"6493caf9-e866-49ce-cd5d-deed02842db8"},"source":["# hint: to select the columns of a matrix corresponding to a set of nonzero coefficients, you can do something like:\n","#don't forget to scale the z's before doing lasso\n","# Z_selected = Z[:,model.coef_!=0]\n","\n","from sklearn import linear_model\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler() #create scaler object\n","scaler.fit(Z) #feed the scaler object the x\n","z_scaled = scaler.transform(Z)\n","\n","\n","lasso = linear_model.Lasso(alpha=0.1)\n","lasso_model = lasso.fit(z_scaled,y)\n","print(lasso_model.coef_)\n","\n","##Unfinished but follow process in notes. THis is cool"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[ 0.          0.         -0.         -0.         -0.         -0.\n","  0.         -0.          0.          0.          0.         -0.\n"," -0.         -0.         -0.         -0.         -0.         -0.\n"," -0.          0.          0.          0.          0.          0.\n","  0.          0.          0.          0.         -0.         -0.\n"," -0.         -0.00460241 -0.         -0.          0.         -0.\n","  0.          0.          0.          0.          0.          0.\n"," -0.         -0.         -0.          0.         -0.         -0.\n","  0.         -0.         -0.         -0.        ]\n"]}]},{"cell_type":"markdown","metadata":{"id":"vJqQvvjdHIHm"},"source":["### Cheat"]},{"cell_type":"code","metadata":{"id":"YJZIyzOuHKN2"},"source":["# Lasso tends to work better with standardized variables, so:\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","scaler.fit(Z)\n","Z_scaled = scaler.transform(Z)\n","\n","# create lasso object, setting the penalty parameter\n","lasso=linear_model.Lasso(alpha=.1)\n","\n","# predict d using Z_scaled:\n","lasso.fit(Z_scaled,d)\n","\n","# grab just the Zs with nonzero coeffs\n","Z_selected=Z_scaled[:,lasso.coef_!=0]\n","\n","# do the first stage regression via OLS using the selected Zs and get the fitted values:\n","postlasso_fs = ols.fit(Z_selected,d)\n","dhat_postlasso = postlasso_fs.predict(Z_selected)\n","\n","# do 2nd stage regression using the post-lasso fitted values:\n","tsls_postlasso = ols.fit(dhat_postlasso,y)\n","print('Post-Lasso 2SLS coefficient: ',tsls_postlasso.coef_)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S0sM-1CWILuG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EZ0b7ysqKuhE"},"source":["## Now go back to ML-augmented 2SLS and try with several different prediction methods"]},{"cell_type":"code","metadata":{"id":"7M9ddYhiK0g3"},"source":[""],"execution_count":null,"outputs":[]}]}
